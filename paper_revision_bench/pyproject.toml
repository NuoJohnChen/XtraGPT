[build-system]
requires = ["setuptools>=61.0", "wheel"]
build-backend = "setuptools.build_meta"

[project]
name = "paper-revision-bench"
version = "0.1.0"
description = "A benchmarking toolkit for evaluating paper revision quality using LLM-as-a-judge"
readme = "README.md"
license = {text = "Apache-2.0"}
authors = [
    {name = "Nuo Chen", email = "nuochen@example.com"},
]
keywords = ["nlp", "paper-revision", "benchmark", "llm", "evaluation"]
classifiers = [
    "Development Status :: 4 - Beta",
    "Intended Audience :: Science/Research",
    "License :: OSI Approved :: Apache Software License",
    "Programming Language :: Python :: 3",
    "Programming Language :: Python :: 3.9",
    "Programming Language :: Python :: 3.10",
    "Programming Language :: Python :: 3.11",
    "Programming Language :: Python :: 3.12",
    "Topic :: Scientific/Engineering :: Artificial Intelligence",
]
requires-python = ">=3.9"
dependencies = [
    "openai>=1.0.0",
    "anthropic>=0.18.0",
    "httpx>=0.25.0",
    "pydantic>=2.0.0",
    "tqdm>=4.65.0",
    "pandas>=2.0.0",
]

[project.optional-dependencies]
dev = [
    "pytest>=7.0.0",
    "pytest-asyncio>=0.21.0",
    "black>=23.0.0",
    "ruff>=0.1.0",
]
all = [
    "vllm>=0.4.0",
]

[project.urls]
Homepage = "https://github.com/Xtra-Computing/paper-revision-bench"
Documentation = "https://github.com/Xtra-Computing/paper-revision-bench#readme"
Repository = "https://github.com/Xtra-Computing/paper-revision-bench"
Issues = "https://github.com/Xtra-Computing/paper-revision-bench/issues"

[tool.setuptools.packages.find]
where = ["."]
include = ["paper_revision_bench*"]

[tool.pytest.ini_options]
asyncio_mode = "auto"

[tool.black]
line-length = 100
target-version = ["py39", "py310", "py311", "py312"]

[project.scripts]
paper-revision-bench = "paper_revision_bench.cli:main"

[tool.ruff]
line-length = 100
select = ["E", "F", "I", "W"]
ignore = ["E501"]
